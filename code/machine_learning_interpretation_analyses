library(rsample)
library(iml)
library(dplyr)
library(h2o)
library(ggplot2)

h2o.no_progress()
h2o.init()


df <- prepped_data_partial %>% 
  mutate_if(is.ordered, factor, ordered = FALSE) %>%
  mutate(job_satisfaction = recode(job_satisfaction, "1" = "1", "2" = "1", "3" = "0", "4" = "0") 
         %>% factor(levels = c("1", "0")))

df <- df %>% 
  select(-id)

df.h2o <- as.h2o(df)

set.seed(123)
splits <- h2o.splitFrame(df.h2o, ratios = c(.7, .15), destination_frames = c("train","valid","test"))
names(splits) <- c("train","valid","test")

y <- "job_satisfaction"
x <- setdiff(names(df), y) 

glm <- h2o.glm(
  x = x, 
  y = y, 
  training_frame = splits$train,
  validation_frame = splits$valid,
  family = "binomial",
  seed = 123
)

rf <- h2o.randomForest(
  x = x, 
  y = y,
  training_frame = splits$train,
  validation_frame = splits$valid,
  ntrees = 1000,
  stopping_metric = "AUC",    
  stopping_rounds = 10,         
  stopping_tolerance = 0.005,
  seed = 123
)

gbm <-  h2o.gbm(
  x = x, 
  y = y,
  training_frame = splits$train,
  validation_frame = splits$valid,
  ntrees = 1000,
  stopping_metric = "AUC",    
  stopping_rounds = 10,         
  stopping_tolerance = 0.005,
  seed = 123
)

# model performance
h2o.auc(glm, valid = TRUE)
## [1] 0.6320015
h2o.auc(rf, valid = TRUE)
## [1] 0.8906868
h2o.auc(gbm, valid = TRUE)
## [1] 0.8012842

# 1. create a data frame with just the features
features <- as.data.frame(splits$valid) %>% select(-job_satisfaction)

# 2. Create a vector with the actual responses
response <- as.numeric(as.vector(splits$valid$job_satisfaction))

# 3. Create custom predict function that returns the predicted values as a
#    vector (probability of purchasing in our example)
pred <- function(model, newdata)  {
  results <- as.data.frame(h2o.predict(model, as.h2o(newdata)))
  return(results[[3L]])
}


# create predictor object to pass to explainer functions
predictor.glm <- Predictor$new(
  model = glm, 
  data = features, 
  y = response, 
  predict.fun = pred,
  class = "classification"
)

predictor.rf <- Predictor$new(
  model = rf, 
  data = features, 
  y = response, 
  predict.fun = pred,
  class = "classification"
)

# compute feature importance with specified loss metric
imp.glm <- FeatureImp$new(predictor.glm, loss = "mse")
imp.rf <- FeatureImp$new(predictor.rf, loss = "mse")

# plot output
p1 <- plot(imp.glm) + ggtitle("GLM")
p2 <- plot(imp.rf) + ggtitle("RF")

gridExtra::grid.arrange(p1, p2, nrow = 1)

glm.ot <- Partial$new(predictor.glm, "influence_own_life") %>% plot() + ggtitle("GLM")
rf.ot <- Partial$new(predictor.rf, "influence_own_life") %>% plot() + ggtitle("RF") 

# plot
gridExtra::grid.arrange(interact.glm, interact.rf, nrow = 1)

# GLM model
glm.age <- Partial$new(predictor.glm, "influence_own_life", ice = TRUE, grid.size = 50)
glm.age$center(min(features$influence_own_life))
p1 <- plot(glm.age) + ggtitle("GLM")

# RF model
rf.age <- Partial$new(predictor.rf, "influence_own_life", ice = TRUE, grid.size = 50)
rf.age$center(min(features$influence_own_life))
p2 <- plot(rf.age) + ggtitle("RF")

gridExtra::grid.arrange(p1, p2, nrow = 1)

p1 <- Partial$new(predictor.glm, c("influence_own_life", "jobs_since_last_interview")) %>% plot() + ggtitle("GLM") + ylim(c(0, .4))
p2 <- Partial$new(predictor.rf, c("influence_own_life", "jobs_since_last_interview")) %>% plot() + ggtitle("RF") + ylim(c(0, .4))

gridExtra::grid.arrange(p1, p2, nrow = 1)

# identify variables with largest interactions in each model
interact.glm <- Interaction$new(predictor.glm) %>% plot() + ggtitle("GLM")
interact.rf  <- Interaction$new(predictor.rf) %>% plot() + ggtitle("RF")

# plot
gridExtra::grid.arrange(interact.glm, interact.rf, nrow = 1)

# identify variables with largest interactions
interact.glm1 <- Interaction$new(predictor.glm, feature = "ethnicity") %>% plot()
interact.rf1  <- Interaction$new(predictor.rf, feature = "ethnicity") %>% plot()

interact.glm2 <- Interaction$new(predictor.glm, feature = "hourly_pay") %>% plot()
interact.rf2  <- Interaction$new(predictor.rf, feature = "hourly_pay") %>% plot()

# plot
gridExtra::grid.arrange(interact.glm1, interact.rf1, nrow = 1)
gridExtra::grid.arrange(interact.glm2, interact.rf2, nrow = 1)

# GLM model ICE hourly_pay
glm.age <- Partial$new(predictor.glm, "hourly_pay", ice = TRUE, grid.size = 50)
glm.age$center(min(features$hourly_pay))
p1 <- plot(glm.age) + ggtitle("GLM")

# RF model ICE hourly_pay
rf.age <- Partial$new(predictor.rf, "hourly_pay", ice = TRUE, grid.size = 50)
rf.age$center(min(features$influence_own_life))
p2 <- plot(rf.age) + ggtitle("RF")

gridExtra::grid.arrange(p1, p2, nrow = 2)

#plot interaction
p11 <- Partial$new(predictor.glm, c("hourly_pay", "ethnicity")) %>% plot() + ggtitle("GLM")+
theme(legend.position="bottom")
p11


# identify obs with highest and lowest probabilities
(high <- predict(rf, splits$valid) %>% .[, 3] %>% as.vector() %>% which.max()) 
## [1] 953
(low  <- predict(rf, splits$valid) %>% .[, 3] %>% as.vector() %>% which.min())  
## [1] 1421

# get these observations
high_prob_ob <- features[high, ]
low_prob_ob  <- features[low, ]

# fit local model
lime.glm <- LocalModel$new(predictor.glm, k = 10, x.interest = high_prob_ob) %>% plot() + ggtitle("GLM")
lime.rf  <- LocalModel$new(predictor.rf, k = 10, x.interest = high_prob_ob) %>% plot() + ggtitle("RF")

gridExtra::grid.arrange(lime.glm, lime.rf, nrow = 1)

# compute Shapley values
shapley.rf <- Shapley$new(predictor.rf, x.interest = high_prob_ob)

# look at summary of results
shapley.rf

shapley.glm <- Shapley$new(predictor.glm, x.interest = high_prob_ob) %>% plot() + ggtitle("GLM")
shapley.rf  <- plot(shapley.rf) + ggtitle("RF")

gridExtra::grid.arrange(shapley.glm, shapley.rf, nrow = 1)

shapley.glm <- Shapley$new(predictor.glm, x.interest = low_prob_ob) %>% plot() + ggtitle("GLM")
shapley.rf  <- Shapley$new(predictor.rf, x.interest = low_prob_ob) %>% plot() + ggtitle("RF")


gridExtra::grid.arrange(shapley.glm, shapley.rf, nrow = 1)
